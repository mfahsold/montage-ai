apiVersion: v1
kind: ConfigMap
metadata:
  name: montage-ai-config
  namespace: montage-ai
  labels:
    app.kubernetes.io/name: montage-ai
data:
  # Creative Direction
  CUT_STYLE: "dynamic"
  CREATIVE_PROMPT: ""
  
  # AI / LLM Configuration
  # Priority: OPENAI_API_BASE > GOOGLE_API_KEY > CGPU > OLLAMA
  
  # Option 1: OpenAI-compatible endpoint (KubeAI, vLLM, LocalAI) - RECOMMENDED
  OPENAI_API_BASE: "http://kubeai.kubeai-system.svc.cluster.local/openai/v1"
  OPENAI_API_KEY: "not-needed"
  OPENAI_MODEL: "gemma3-4b"  # Or: qwen2-5-32b, llava-7b, etc.
  
  # Option 2: Ollama (local fallback)
  OLLAMA_HOST: "http://ollama.montage-ai.svc.cluster.local:11434"
  OLLAMA_MODEL: "llava"
  DIRECTOR_MODEL: "llama3.1:70b"
  
  # Option 3: cgpu (cloud GPU + Gemini LLM)
  CGPU_ENABLED: "false"
  CGPU_HOST: "cgpu-server.montage-ai.svc.cluster.local"
  CGPU_PORT: "8080"
  CGPU_MODEL: "gemini-2.0-flash"
  CGPU_GPU_ENABLED: "false"
  CGPU_TIMEOUT: "600"
  
  # Enhancement Settings
  STABILIZE: "true"
  UPSCALE: "false"
  ENHANCE: "true"
  ENABLE_AI_FILTER: "true"
  
  # Output Configuration
  NUM_VARIANTS: "1"
  VERBOSE: "true"
  EXPORT_TIMELINE: "true"  # Export OTIO/EDL/CSV for professional NLE software
  GENERATE_PROXIES: "false"
  
  # Performance
  FFMPEG_THREADS: "0"
  FFMPEG_PRESET: "medium"
  PARALLEL_ENHANCE: "true"
  MAX_PARALLEL_JOBS: "4"
  USE_GPU: "auto"
  MONITOR_MEM_INTERVAL: "5"
  MAX_SCENE_REUSE: "3"
  USE_FFMPEG_MCP: "false"
  FFMPEG_MCP_ENDPOINT: "http://ffmpeg-mcp.montage-ai.svc.cluster.local:8080"
  FINAL_CRF: "18"               # Quality: 18=master, 23=fast preview
  NORMALIZE_CLIPS: "true"       # Normalize fps/pix_fmt before concat
  ENABLE_XFADE: ""              # "", true, false ("" = follow style)
  XFADE_DURATION: "0.3"         # Seconds, only if ENABLE_XFADE=true
  
  # Deep Analysis
  DEEP_ANALYSIS: "false"
