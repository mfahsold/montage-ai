# Docker Compose for Montage AI Web UI
#
# Usage:
#   docker-compose -f docker-compose.web.yml up

services:
  web-ui:
    build: .
    entrypoint: ["python", "-u", "-m", "montage_ai.web_ui.app"]
    ports:
      - "5001:5000"  # Using 5001 as 5000 is used by registry
    volumes:
      - ./data:/data
      # Development: Mount source for live updates (remove in production)
      - ./src:/app/src:ro
      # cgpu Cloud GPU credentials (cgpu binary is installed in Docker image)
      - ${HOME}/.config/cgpu:/root/.config/cgpu:ro
    environment:
      - FLASK_ENV=production
      - INPUT_DIR=/data/input
      - MUSIC_DIR=/data/music
      - OUTPUT_DIR=/data/output
      - OLLAMA_HOST=http://host.docker.internal:11434
      # cgpu Cloud GPU for upscaling (uses Google Colab T4)
      - CGPU_GPU_ENABLED=true
      - CGPU_TIMEOUT=600
      # cgpu LLM serve (separate feature, disabled for now)
      - CGPU_ENABLED=false
      - VERBOSE=true
      - MAX_CONCURRENT_JOBS=2
    restart: unless-stopped
    # Resource limits to prevent OOM
    deploy:
      resources:
        limits:
          memory: 8G      # Prevent container from consuming all system RAM
          cpus: '4.0'     # Limit CPU usage to 4 cores
        reservations:
          memory: 2G      # Guarantee minimum 2GB
          cpus: '1.0'     # Guarantee minimum 1 core
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/api/status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
