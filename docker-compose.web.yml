# Docker Compose for Montage AI Web UI
#
# Usage:
#   docker compose -f docker-compose.web.yml up
#
# Environment variables (optional):
#   CGPU_GPU_ENABLED=true  - Enable cloud GPU for upscaling
#   CGPU_ENABLED=true      - Enable cgpu LLM serve
#   GOOGLE_API_KEY=xxx     - Google AI API key

services:
  web-ui:
    build: .
    entrypoint: ["python", "-u", "-m", "montage_ai.web_ui.app"]
    ports:
      - "${WEB_PORT:-5001}:5000"
    volumes:
      - ./data:/data
      # cgpu Cloud GPU credentials (optional)
      - ${HOME}/.config/cgpu:/root/.config/cgpu:ro
    environment:
      - FLASK_ENV=${FLASK_ENV:-production}
      - INPUT_DIR=${INPUT_DIR:-/data/input}
      - MUSIC_DIR=${MUSIC_DIR:-/data/music}
      - OUTPUT_DIR=${OUTPUT_DIR:-/data/output}
      - OLLAMA_HOST=${OLLAMA_HOST:-http://host.docker.internal:11434}
      # Google AI (preferred LLM backend)
      - GOOGLE_API_KEY=${GOOGLE_API_KEY:-}
      - GOOGLE_AI_MODEL=${GOOGLE_AI_MODEL:-gemini-2.0-flash}
      # cgpu Cloud GPU for upscaling
      - CGPU_GPU_ENABLED=${CGPU_GPU_ENABLED:-false}
      - CGPU_TIMEOUT=${CGPU_TIMEOUT:-1200}
      # cgpu LLM serve (alternative to Google AI)
      - CGPU_ENABLED=${CGPU_ENABLED:-false}
      - VERBOSE=${VERBOSE:-true}
      - MAX_CONCURRENT_JOBS=${MAX_CONCURRENT_JOBS:-2}
    restart: unless-stopped
    # Resource limits (override via env values)
    deploy:
      resources:
        limits:
          memory: ${WEB_MEMORY_LIMIT:-8G}
          cpus: '${WEB_CPU_LIMIT:-4.0}'
        reservations:
          memory: ${WEB_MEMORY_RESERVATION:-2G}
          cpus: '${WEB_CPU_RESERVATION:-1.0}'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/api/status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
