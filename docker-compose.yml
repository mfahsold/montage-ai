services:
  montage-ai:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        # Pass git commit hash for version tracking
        GIT_COMMIT: ${GIT_COMMIT:-dev}
    image: montage-ai:latest
    container_name: montage-ai
    # === RESOURCE LIMITS (IMPORTANT for stability) ===
    # Uncomment and adjust based on your system:
    # - For 32GB RAM system: mem_limit: 24g (leaves 8GB for OS)
    # - For 16GB RAM system: mem_limit: 12g (leaves 4GB for OS)
    # - For  8GB RAM system: mem_limit:  6g (leaves 2GB for OS)
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8g  # Reduced from 16g to prevent OOM on ARM systems
        reservations:
          memory: 2g   # Reduced from 4g
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./data/input:/data/input:ro
      - ./data/music:/data/music:ro
      - ./data/assets:/data/assets:ro
      - ./data/output:/data/output
      # LUT files for professional color grading (optional)
      - ./data/luts:/data/luts:ro
      # cgpu Cloud GPU credentials (cgpu binary is installed in Docker image)
      - ${HOME}/.config/cgpu:/root/.config/cgpu:ro
    environment:
      # Creative Direction
      - CREATIVE_PROMPT=${CREATIVE_PROMPT:-}
      - CUT_STYLE=${CUT_STYLE:-dynamic}
      
      # Color Grading / LUTs
      - LUT_DIR=${LUT_DIR:-/data/luts}
      - COLOR_MATCH=${COLOR_MATCH:-false}
      
      # AI / LLM Configuration
      # Priority: OPENAI_API_BASE > GOOGLE_API_KEY > CGPU > OLLAMA
      
      # OpenAI-compatible API (KubeAI, vLLM, LocalAI, etc.) - PREFERRED
      - OPENAI_API_BASE=${OPENAI_API_BASE:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-not-needed}
      - OPENAI_MODEL=${OPENAI_MODEL:-}  # Creative Director (e.g. gemma3-4b, qwen2-5-32b)
      - OPENAI_VISION_MODEL=${OPENAI_VISION_MODEL:-}  # Scene analysis (e.g. moondream2, llava-7b)
      
      # Ollama (local fallback)
      - OLLAMA_HOST=${OLLAMA_HOST:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llava}
      - DIRECTOR_MODEL=${DIRECTOR_MODEL:-llama3.1:70b}
      - ENABLE_AI_FILTER=${ENABLE_AI_FILTER:-false}
      
      # LLM-powered clip selection (uses configured LLM backend) - enabled by default
      - LLM_CLIP_SELECTION=${LLM_CLIP_SELECTION:-true}
      
      # Google AI (direct API)
      - GOOGLE_API_KEY=${GOOGLE_API_KEY:-}
      - GOOGLE_AI_MODEL=${GOOGLE_AI_MODEL:-gemini-2.0-flash}
      
      # cgpu Integration (Cloud GPU + Gemini LLM via cgpu serve)
      - CGPU_ENABLED=${CGPU_ENABLED:-false}
      - CGPU_HOST=${CGPU_HOST:-host.docker.internal}
      - CGPU_PORT=${CGPU_PORT:-8090}
      - CGPU_MODEL=${CGPU_MODEL:-gemini-2.0-flash}
      - CGPU_GPU_ENABLED=${CGPU_GPU_ENABLED:-false}
      - CGPU_TIMEOUT=${CGPU_TIMEOUT:-1800}  # 30 min for large videos (was 600)
      
      # Enhancement Settings
      - STABILIZE=${STABILIZE:-false}
      - UPSCALE=${UPSCALE:-false}
      - ENHANCE=${ENHANCE:-true}
      
      # Aspect Ratio Handling
      # false (default): Crop to fill frame (may cut edges)
      # true: Letterbox/pillarbox to preserve full content
      - PRESERVE_ASPECT=${PRESERVE_ASPECT:-false}
      
      # Output Configuration
      - NUM_VARIANTS=${NUM_VARIANTS:-1}
      - VERBOSE=${VERBOSE:-true}
      - EXPORT_TIMELINE=${EXPORT_TIMELINE:-false}
      - GENERATE_PROXIES=${GENERATE_PROXIES:-false}
      
      # Performance (optimized for memory constraints)
      - FFMPEG_THREADS=${FFMPEG_THREADS:-0}
      - FFMPEG_PRESET=${FFMPEG_PRESET:-medium}
      - PARALLEL_ENHANCE=${PARALLEL_ENHANCE:-true}
      - MAX_PARALLEL_JOBS=${MAX_PARALLEL_JOBS:-2}  # Reduced from 4 to prevent OOM
      - USE_GPU=${USE_GPU:-auto}
      
      # FFmpeg Hardware Acceleration (GPU encoding/decoding)
      # Options: auto (detect), nvenc (NVIDIA), vaapi (AMD/Intel), qsv (Intel), none (CPU)
      - FFMPEG_HWACCEL=${FFMPEG_HWACCEL:-auto}

      # Memory Management (optimized for ARM systems)
      - MEMORY_LIMIT_GB=${MEMORY_LIMIT_GB:-8}  # Match docker mem_limit (reduced from 16)
      - MAX_CLIPS_IN_RAM=${MAX_CLIPS_IN_RAM:-20}  # Limit simultaneous clips (reduced from 50)
      - AUTO_CLEANUP=${AUTO_CLEANUP:-true}  # Enable temp file cleanup
      
      # Deep Analysis
      - DEEP_ANALYSIS=${DEEP_ANALYSIS:-false}
    # === GPU ACCESS (for hardware video encoding) ===
    # Uncomment for NVIDIA GPU:
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu, video]
    # 
    # For AMD/Intel VAAPI, add:
    devices:
      - /dev/dri:/dev/dri  # VAAPI/VA-API access for AMD/Intel GPU
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: "no"
