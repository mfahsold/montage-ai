services:
  montage-ai:
    build:
      context: .
      dockerfile: Dockerfile
    image: montage-ai:latest
    container_name: montage-ai
    cpus: 6
    mem_limit: 24g
    volumes:
      - ./data/input:/data/input:ro
      - ./data/music:/data/music:ro
      - ./data/assets:/data/assets:ro
      - ./data/output:/data/output
    environment:
      # Creative Direction
      - CREATIVE_PROMPT=${CREATIVE_PROMPT:-}
      - CUT_STYLE=${CUT_STYLE:-dynamic}
      
      # AI / LLM Configuration (Ollama - local fallback)
      - OLLAMA_HOST=${OLLAMA_HOST:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llava}
      - DIRECTOR_MODEL=${DIRECTOR_MODEL:-llama3.1:70b}
      - ENABLE_AI_FILTER=${ENABLE_AI_FILTER:-false}
      
      # Google AI (direct API - preferred for LLM)
      - GOOGLE_API_KEY=${GOOGLE_API_KEY:-}
      - GOOGLE_AI_MODEL=${GOOGLE_AI_MODEL:-gemini-2.0-flash}
      
      # cgpu Integration (Cloud GPU + Gemini LLM via cgpu serve)
      - CGPU_ENABLED=${CGPU_ENABLED:-false}
      - CGPU_HOST=${CGPU_HOST:-host.docker.internal}
      - CGPU_PORT=${CGPU_PORT:-8080}
      - CGPU_MODEL=${CGPU_MODEL:-gemini-2.0-flash}
      - CGPU_GPU_ENABLED=${CGPU_GPU_ENABLED:-false}
      - CGPU_TIMEOUT=${CGPU_TIMEOUT:-600}
      
      # Enhancement Settings
      - STABILIZE=${STABILIZE:-false}
      - UPSCALE=${UPSCALE:-false}
      - ENHANCE=${ENHANCE:-true}
      
      # Output Configuration
      - NUM_VARIANTS=${NUM_VARIANTS:-1}
      - VERBOSE=${VERBOSE:-true}
      - EXPORT_TIMELINE=${EXPORT_TIMELINE:-false}
      - GENERATE_PROXIES=${GENERATE_PROXIES:-false}
      
      # Performance
      - FFMPEG_THREADS=${FFMPEG_THREADS:-0}
      - FFMPEG_PRESET=${FFMPEG_PRESET:-medium}
      - PARALLEL_ENHANCE=${PARALLEL_ENHANCE:-true}
      - MAX_PARALLEL_JOBS=${MAX_PARALLEL_JOBS:-4}
      - USE_GPU=${USE_GPU:-auto}
      
      # Deep Analysis
      - DEEP_ANALYSIS=${DEEP_ANALYSIS:-false}
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: "no"
