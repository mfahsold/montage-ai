# AI Director Parameter Tuning - Low-Hanging Fruits

**Status:** âœ… Implemented (Phase 1)  
**Date:** January 9, 2026  
**Architecture:** Central LLM-based parameter suggestion system

## Overview

Montage AI jetzt hat ein **zentrales Parameter-Suggestion-System** fÃ¼r AI-gesteuerte Editing-Optimierung. Alle LLM-Anfragen gehen durch `CreativeDirector` (cgpu-robust mit Ollama-Fallback).

## Product Requirements (PRD-light, single source)

- **User Input**: Intent (Schnitt, Musik, Look, QualitÃ¤tsverbesserungen via Radiobutton/Dropdown/Switch). Kein Parameter-Baukasten.
- **AI Output**: Entscheidungen + BegrÃ¼ndung + Export-Artefakte (OTIO/EDL/Premiere/Resolve-kompatibel). Nutzer sieht â€wasâ€œ und â€warumâ€œ, kann optional einzelne Entscheidungen Ã¼bernehmen/ablehnen.
- **UI-Scope**: Leichtgewichtiges â€AI Decisionsâ€œ-Panel (Anzeige, Reasoning, Confidence, Apply/Decline), plus â€Exportâ€œ Button. Keine tiefen Parameter-Slider.
- **Backend**: Alle LLM-Calls Ã¼ber `CreativeDirector._query_backend()` mit Fallback-Kette (OpenAI-API â†’ cgpu â†’ Google AI â†’ Ollama). cgpu kann fÃ¼r Heavy Load genutzt werden.
- **Philosophie**: â€Polish, donâ€™t generateâ€œ â€“ wir optimieren Schnitt, Look, Stabilisierung; kein Pixel-Gen.

## Export-Pipeline (Design Draft)

- **Quelle**: EditingParameters + Timeline/Clip-Metadaten (shots, in/out, audio beats, style)
- **Zielartefakte**: PrimÃ¤r OTIO, davon abgeleitet EDL/AAF/Premiere XML/Resolve (wo sinnvoll)
- **Color Grading**: Als Note/LUT-Hinweis; wenn gerendert angewendet â†’ Note â€bakedâ€œ. Sonst â€recommendedâ€œ im Export-Note-Track
- **Stabilisierung**: Analog Color; Flag â€appliedâ€œ vs â€recommendedâ€œ je Clip
- **Audio/Musik**: Timeline-Events (start timecode, in/out, track id), Beat-Marker fÃ¼r Pacing
- **Pacing/Beats**: Marker je Schnitt (â€cut at beat nâ€œ, â€section=intro/build/climax/outroâ€œ)
- **QualitÃ¤tsverbesserungen**: Clip-Notes (â€denoise appliedâ€œ, â€sharpen offâ€œ, â€upscale disabledâ€œ)
- **Roundtrip**: Import EditingParameters-JSON + OTIO â†’ rekonstruierbare Decisions ohne Feldverlust

## Changelog (kurz)

- 2026-01-09: Intent-in/Decisions-out verankert; Director-Systemprompt export-ready; Preset-Single-Source auf color_grading; Suggester nutzt dieselben Presets.

## âœ… Was ist jetzt implementiert


### 1. Unified Parameter Schema (`editing_parameters.py`)

**Zweck:** Zentrale Parameterdefinition fÃ¼r alle Editing-Domains  
**Impact:** ğŸŸ¢ HIGH - Verhindert Parameter-Fragmentierung


```python
from montage_ai.editing_parameters import EditingParameters

# Alle tunable Parameter in einem Schema

params = EditingParameters()
params.stabilization.smoothing = 20
params.color_grading.preset = "teal_orange"
params.color_grading.intensity = 0.9
params.pacing.speed = PacingSpeed.DYNAMIC
params.validate()  # Validiert alle Ranges

```

**Parameter-Gruppen:**

- **Stabilization:** 8 Parameter (smoothing, shakiness, accuracy, stepsize, zoom, optzoom, crop, method)
- **Color Grading:** 9 Parameter (preset, intensity, LUT, temperature, tint, saturation, contrast, brightness, normalize)
- **Clip Selection:** 10 Parameter (bonus/penalty-Faktoren, weights, LLM-ranking)
- **Pacing:** 10+ Parameter (speed, pattern, chaos_factor, beat-syncing, Fibonacci sequences)

**Total:** 50+ tunable Parameter, zentral validiert und serialisierbar (JSON).

---

### 2. LLM-based Parameter Suggester (`parameter_suggester.py`)

**Zweck:** AI-gesteuerte intelligente Parameter-Optimierung  
**Impact:** ğŸŸ¢ HIGH - Automatisiert manuelle Tuning-Decisions

#### Base Class: `ParameterSuggester`

Zentrale Abstraktion fÃ¼r alle LLM-basierten Suggester:

- Nutzt `CreativeDirector` fÃ¼r LLM-Backend (cgpu/Ollama/Gemini)
- Robust gegen cgpu-AusfÃ¤lle (automatischer Fallback)
- Typed responses mit Reasoning

#### Implementierte Suggester


##### a) `ColorGradingSuggester` (ğŸ”¥ HIGH VALUE)

**Problem:** Color grading requires artistic expertise  
**LÃ¶sung:** LLM analysiert Scene + Intent â†’ schlÃ¤gt Preset + Parameter vor


```python
from montage_ai.parameter_suggester import ColorGradingSuggester

suggester = ColorGradingSuggester()  # Auto-detects cgpu/Ollama
context = {
    "scene_description": "sunset beach with warm orange sky",
    "user_intent": "cinematic blockbuster",
    "dominant_colors": ["orange", "blue"],
    "histogram": {"shadows": 0.25, "midtones": 0.50, "highlights": 0.25}
}

suggestion = suggester.suggest(context)

# suggestion.parameters = {

#   "preset": "golden_hour",

#   "intensity": 0.9,

#   "temperature": 0.3,  # Warmer

#   "saturation": 1.2,

#   ...

# }

# suggestion.reasoning = "Golden hour preset enhances warm sunset tones..."

# suggestion.confidence = 0.85

```

**Features:**

- 20+ Presets (teal_orange, cinematic, blockbuster, vintage, noir, etc.)
- Histogram-aware Adjustments
- Confidence Scores
- Explained Decisions (LLM reasoning)

##### b) `StabilizationTuner` (ğŸŸ¡ MEDIUM VALUE)

**Problem:** Stabilization parameter tuning requires shake analysis expertise  
**LÃ¶sung:** LLM analysiert shake_score + motion_type â†’ optimiert vidstab-Parameter


```python
from montage_ai.parameter_suggester import StabilizationTuner

tuner = StabilizationTuner()
context = {
    "shake_score": 0.7,  # 0-1 scale (0=stable, 1=very shaky)
    "motion_type": "handheld",
    "resolution": "1080p",
    "user_intent": "smooth cinematic motion"
}

suggestion = tuner.suggest(context)

# suggestion.parameters = {

#   "smoothing": 20,  # Higher for shakier footage

#   "shakiness": 7,

#   "accuracy": 12,

#   "zoom": 5,  # Slight zoom to crop borders

#   ...

# }

```

**Integration mit cgpu:**

- `StabilizeJob` in `cgpu_jobs/stabilize.py` nutzt die vorgeschlagenen Parameter
- Parameter werden geclampt (1-30 fÃ¼r smoothing, etc.)
- Robust gegen invalide LLM-Ausgaben (Fallback zu safe defaults)

---

### 3. Zentrale LLM-Integration (`creative_director.py`)

**Neu hinzugefÃ¼gt:** `_query_backend()` Methode


```python
class CreativeDirector:
    def _query_backend(
        self,
        prompt: str,
        temperature: float = 0.3,
        max_tokens: int = 1024,
        system_prompt: Optional[str] = None
    ) -> str:
        """
        Generic LLM query fÃ¼r non-editing tasks (parameter suggestion).
        Versucht Backends in Reihenfolge: OpenAI-API â†’ cgpu â†’ Google AI â†’ Ollama
        """

```

**Warum zentral?**

- âœ… Ein Ort fÃ¼r Backend-Fallback-Logik
- âœ… cgpu-Robustheit garantiert (auto-fallback zu Ollama)
- âœ… Keine duplizierten LLM-Calls in verschiedenen Modulen
- âœ… Konsistente Fehlerbehandlung

---

## ğŸ“Š Implementierungs-Status

| Feature | Status | Impact | Effort | Datei |
| --- | --- | --- | --- | --- |
| **Unified Parameter Schema** | âœ… Done | ğŸŸ¢ HIGH | 2h | `editing_parameters.py` |
| **ColorGradingSuggester** | âœ… Done | ğŸŸ¢ HIGH | 5h | `parameter_suggester.py` |
| **StabilizationTuner** | âœ… Done | ğŸŸ¡ MEDIUM | 3h | `parameter_suggester.py` |
| **Central LLM Integration** | âœ… Done | ğŸŸ¢ HIGH | 1h | `creative_director.py` |
| **Convenience Functions** | âœ… Done | ğŸŸ¢ HIGH | 1h | `parameter_suggester.py` |
| **Test Suite** | âœ… Done | ğŸŸ¡ MEDIUM | 2h | `test_parameter_suggester.py` |
| **PacingAdvisor** | â³ Planned | ğŸŸ¡ MEDIUM | 4h | - |
| **Web UI Integration** | â³ Planned | ğŸŸ¢ HIGH | 6h | - |

**Total Effort (Phase 1):** ~14 hours  
**Total Effort (Phase 2):** ~10 hours

---

## ğŸš€ Usage Examples

### Quick Start (Convenience Functions)


```python

# 1. Quick color grading

from montage_ai.parameter_suggester import suggest_color_grading

params = suggest_color_grading(
    scene_description="night city with neon lights",
    user_intent="cyberpunk atmosphere"
)

# Returns: ColorGradingParameters with preset="cool", intensity=0.9, etc.

# 2. Quick stabilization

from montage_ai.parameter_suggester import suggest_stabilization

params = suggest_stabilization(
    shake_score=0.6,
    motion_type="walking"
)

# Returns: StabilizationParameters with smoothing=18, shakiness=6, etc.

```

### Integration in MontageBuilder


```python
from montage_ai.parameter_suggester import ColorGradingSuggester
from montage_ai.core.montage_builder import MontageBuilder

class EnhancedMontageBuilder(MontageBuilder):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.color_suggester = ColorGradingSuggester()
    
    def apply_intelligent_color_grading(self, clip_metadata):
        """Auto-tune color grading based on clip analysis."""
        context = {
            "scene_description": clip_metadata.get("description"),
            "user_intent": self.style_template.get("color_intent", "cinematic"),
            "dominant_colors": clip_metadata.get("color_palette", [])
        }
        
        suggestion = self.color_suggester.suggest(context)
        logger.info(f"AI suggested: {suggestion.parameters['preset']} "
                   f"(confidence: {suggestion.confidence:.2f})")
        logger.info(f"Reasoning: {suggestion.reasoning}")
        
        # Apply suggested parameters
        self.color_grade_config.preset = suggestion.parameters["preset"]
        self.color_grade_config.intensity = suggestion.parameters["intensity"]

```

---

## ğŸ”§ cgpu-Robustness Design

### Problem

cgpu kann ausfallen (Netzwerk, Rate-Limits, API-Ã„nderungen). System muss resilient sein.

### LÃ¶sung: Central Fallback-Chain

Alle LLM-Calls gehen durch `CreativeDirector._query_backend()`:

```text
User Request
    â†“
CreativeDirector._query_backend()
    â†“
1. OpenAI-API (KubeAI/vLLM)  [if configured]
    â†“ (fallback on error)
2. cgpu/Gemini             [if CGPU_ENABLED=true]
    â†“ (fallback on error)
3. Google AI Direct        [if GOOGLE_API_KEY set]
    â†“ (fallback on error)
4. Ollama (Local)          [always available]
    â†“
Response or RuntimeError

```

**Test Coverage:**

```bash

# Test cgpu failure scenario

export CGPU_ENABLED=false
python test_parameter_suggester.py

# â†’ Should fallback to Ollama without errors

```

---

## ğŸ“ˆ Impact Analysis

### Before (Manual Tuning)


```python

# Hard-coded magic numbers

stabilization_smoothing = 15  # Why 15? Unknown.
color_preset = "cinematic"    # Always the same
intensity = 0.8               # Fixed value

```

**Problems:**

- âŒ No scene-specific optimization
- âŒ No reasoning/explanation
- âŒ Requires expert knowledge
- âŒ Not adaptable to user intent

### After (AI-Driven Tuning)


```python

# Context-aware intelligent tuning

suggestion = color_suggester.suggest({
    "scene_description": "dark moody interior",
    "user_intent": "film noir atmosphere"
})

# LLM returns:

# {

#   "preset": "noir",

#   "intensity": 0.95,

#   "contrast": 1.4,

#   "reasoning": "High contrast noir preset enhances shadows..."

# }

```

**Benefits:**

- âœ… Scene-specific optimization
- âœ… Explainable decisions (LLM reasoning)
- âœ… Learns from context (histogram, colors, intent)
- âœ… Adaptable to creative direction

---

## ğŸ¯ Next Steps (Phase 2)

### Priority 1: Web UI Integration (6h)

**Goal:** Expose parameter suggestions in web interface


```html
<!-- montage.html -->
<div class="ai-suggestions-panel">
  <h3>ğŸ¤– AI Parameter Suggestions</h3>
  
  <div class="suggestion color-grading">
    <label>Color Grading</label>
    <p class="reasoning">{{ suggestion.reasoning }}</p>
    <button onclick="applyColorGrading()">Apply Suggestion</button>
  </div>
  
  <div class="suggestion stabilization">
    <label>Stabilization</label>
    <p class="reasoning">{{ suggestion.reasoning }}</p>
    <button onclick="applyStabilization()">Apply Suggestion</button>
  </div>
</div>

```

**API Endpoint:**

```python

# web_ui/app.py

@app.route('/api/suggest-parameters', methods=['POST'])
def suggest_parameters():
    """Return AI-suggested editing parameters."""
    scene_desc = request.json.get('scene_description')
    user_intent = request.json.get('user_intent')
    
    suggester = ColorGradingSuggester()
    suggestion = suggester.suggest({
        "scene_description": scene_desc,
        "user_intent": user_intent
    })
    
    return jsonify({
        "parameters": suggestion.parameters,
        "reasoning": suggestion.reasoning,
        "confidence": suggestion.confidence
    })

```

### Priority 2: PacingAdvisor (4h)

**Goal:** LLM suggests beats_per_cut overrides for specific sections


```python
class PacingAdvisor(ParameterSuggester):
    """
    Suggests pacing adjustments for different video sections.
    
    Example:
        advisor = PacingAdvisor()
        context = {
            "section": "intro",  # intro/build/climax/outro
            "music_energy": 0.3,
            "user_intent": "slow cinematic build"
        }
        suggestion = advisor.suggest(context)
        # suggestion.parameters = {"beats_per_cut": 8, "pattern": "fibonacci"}
    """

```

### Priority 3: Integration Tests (2h)

**Goal:** End-to-end tests mit echten Clips


```python
def test_e2e_color_grading_suggestion():
    """Test full pipeline: clip analysis â†’ LLM suggestion â†’ FFmpeg application."""
    clip_path = "test_data/input/sunset_beach.mp4"
    
    # 1. Analyze clip
    analyzer = ClipAnalyzer()
    metadata = analyzer.analyze(clip_path)
    
    # 2. Get LLM suggestion
    suggester = ColorGradingSuggester()
    suggestion = suggester.suggest({
        "scene_description": metadata["description"],
        "dominant_colors": metadata["color_palette"]
    })
    
    # 3. Apply color grading
    enhancer = ClipEnhancer()
    output = enhancer.apply_color_grade(
        clip_path,
        preset=suggestion.parameters["preset"],
        intensity=suggestion.parameters["intensity"]
    )
    
    assert output.exists()

```

---

## ğŸ“ Design Decisions

### 1. Warum zentrale Mechanismen?

**Problem:** Wenn jeder Modul eigene LLM-Calls macht:

- 10 Orte mit Backend-Selection-Logic
- 10 Orte mit Fehlerbehandlung
- 10 Orte fÃ¼r cgpu-Fallback-Code
- Inkonsistente Timeouts, Retry-Logic

**LÃ¶sung:** `CreativeDirector` als Single Source of Truth

- âœ… Backend-Selection: 1 Ort (`__init__`)
- âœ… Fallback-Logic: 1 Ort (`_query_backend()`)
- âœ… Timeout-Config: 1 Ort (`LLMConfig`)
- âœ… cgpu-Robustheit: Automatisch fÃ¼r alle Suggester

### 2. Warum EditingParameters Schema?

**Problem:** Parameter scattered across modules

- `color_grading.py`: ColorGradeConfig
- `cgpu_jobs/stabilize.py`: Constructor params
- `core/pacing_engine.py`: Various dicts
- Keine zentrale Validierung

**LÃ¶sung:** Unified typed schema

- âœ… Single source of truth fÃ¼r Parameter-Ranges
- âœ… JSON-serialisierbar (fÃ¼r API, Storage)
- âœ… Type-safe (Enums, dataclasses)
- âœ… Self-documenting (docstrings)

### 3. Warum LLM statt Heuristiken?

**Heuristik-Ansatz:**

```python
if shake_score > 0.7:
    smoothing = 20
elif shake_score > 0.4:
    smoothing = 15
else:
    smoothing = 10

```

**Probleme:**

- âŒ Rigid rules
- âŒ No context awareness
- âŒ No reasoning
- âŒ Schwer zu maintainen

**LLM-Ansatz:**

```python
suggestion = tuner.suggest({
    "shake_score": 0.7,
    "motion_type": "handheld",  # Context!
    "user_intent": "smooth"      # Intent!
})

```

**Vorteile:**

- âœ… Context-aware (motion_type, resolution, intent)
- âœ… Explainable (reasoning field)
- âœ… Adaptiv (lernt von Prompt)
- âœ… Erweiterbar (neue Faktoren â†’ Prompt-Update)

---

## ğŸ§ª Testing

### Run Tests


```bash
cd /home/codeai/montage-ai
python test_parameter_suggester.py

```

### Expected Output

```text
================================================================================
LLM-BASED PARAMETER SUGGESTION SYSTEM TESTS
Testing cgpu-robust AI director parameter tuning
================================================================================

================================================================================
TEST 1: Color Grading Suggestion
================================================================================

--- Scene 1: Sunset Beach ---
Suggested Preset: golden_hour
Intensity: 0.90
Temperature: 0.30
Saturation: 1.20
Confidence: 0.85
Reasoning: Golden hour preset enhances warm sunset tones with increased
saturation to emphasize orange/yellow hues. Positive temperature shift adds
warmth. High confidence due to clear scene characteristics.

--- Scene 2: Night City ---
Suggested Preset: cool
Intensity: 0.85
Temperature: -0.40
Confidence: 0.80
Reasoning: Cool preset with negative temperature shift creates cyberpunk
atmosphere. Desaturated look enhances neon lights contrast.

[... weitere Tests ...]

================================================================================
ALL TESTS COMPLETED
================================================================================

```

---

## ğŸ“š References

### Related Files

- `src/montage_ai/editing_parameters.py` - Parameter schema
- `src/montage_ai/parameter_suggester.py` - LLM suggester system
- `src/montage_ai/creative_director.py` - LLM backend (updated)
- `src/montage_ai/color_grading.py` - Color grading implementation
- `src/montage_ai/cgpu_jobs/stabilize.py` - Stabilization job
- `test_parameter_suggester.py` - Test suite

### External Research

- DirectorLLM: LLM-based cinematography orchestration
- Descript Underlord: Conversational video editing
- LAVE: Structured JSON for video editing agents

---

## âœ… Success Criteria

**Phase 1 (Done):**

- [x] Zentrale Parameter-Schema erstellt
- [x] ColorGradingSuggester implementiert
- [x] StabilizationTuner implementiert
- [x] CreativeDirector._query_backend() hinzugefÃ¼gt
- [x] cgpu-Robustheit getestet
- [x] Convenience functions fÃ¼r quick usage
- [x] Test suite erstellt

**Phase 2 (Planned):**

- [ ] Web UI integration (Suggestions Panel)
- [ ] PacingAdvisor implementiert
- [ ] End-to-end tests mit echten Clips
- [ ] Performance benchmarks (LLM latency)
- [ ] Dokumentation fÃ¼r User (README update)

---

## ğŸ“¤ Export to NLE (CLI + API)

**Status:** âœ… Implemented (Phase 1.5)

### Overview

Montage AI kann Timelines jetzt zu professionellen NLE-Formaten exportieren:

- **OTIO** (OpenTimelineIO) - Canonical format mit vollem Metadata
- **EDL** (CMX 3600) - KompatibilitÃ¤t mit allen Legacy-Systemen
- **Premiere XML** - Adobe Premiere Pro
- **AAF** - Avid Media Composer
- **JSON Parameters** - Roundtrip: Export â†’ NLE-Edit â†’ Re-import

### CLI Usage

```bash
# Export zu OTIO (Standard)
./montage-ai.sh export-to-nle --manifest /data/output/manifest.json

# Export zu mehreren Formaten
./montage-ai.sh export-to-nle --manifest /data/output/manifest.json \
  --formats otio edl premiere aaf \
  --project-name "My Project" \
  --output-dir /data/output

# Mit EditingParameters JSON
./montage-ai.sh export-to-nle \
  --manifest /data/output/manifest.json \
  --params /data/output/parameters.json
```

### Python API

```python
from montage_ai.export import export_to_nle, create_export_summary
from montage_ai.export.otio_builder import TimelineClipInfo
from montage_ai.editing_parameters import EditingParameters
from pathlib import Path

# Prepare clips
clips = [
    TimelineClipInfo(
        source_path="/data/input/clip1.mp4",
        in_time=0.0,
        out_time=5.0,
        duration=5.0,
        sequence_number=1,
        applied_effects={
            "color_grading": {"preset": "teal_orange", "intensity": 0.9},
            "stabilization": {"smoothing": 20}
        },
        confidence_scores={"color_grading": 0.85}
    ),
    # ... more clips
]

# Export
params = EditingParameters()
results = export_to_nle(
    timeline_clips=clips,
    editing_params=params,
    output_dir=Path("/data/output"),
    formats=["otio", "edl", "premiere"],
    project_name="My Montage"
)

# Summary
print(create_export_summary(results))
```

### Manifest Format

Timeline manifest JSON (from MontageBuilder):

```json
{
  "clips": [
    {
      "source_path": "/data/input/clip1.mp4",
      "in_time": 0.0,
      "out_time": 5.0,
      "duration": 5.0,
      "sequence_number": 1,
      "applied_effects": {
        "color_grading": {"preset": "teal_orange"},
        "stabilization": {"smoothing": 20}
      },
      "recommended_effects": {...},
      "confidence_scores": {"color_grading": 0.85}
    }
  ],
  "beat_timecodes": [[1.0, "beat_1"], [2.0, "beat_2"]],
  "section_markers": [[0.0, "intro"], [2.0, "build"], [4.0, "climax"]]
}
```

### Metadata Attachment

Alle Effects werden als Clip-Metadaten exportiert:

```
Clip Metadata (OTIO):
â”œâ”€â”€ montage_ai.applied_effects        # Effects already applied (baked)
â”œâ”€â”€ montage_ai.recommended_effects    # Suggestions for NLE user
â”œâ”€â”€ montage_ai.confidence_scores      # LLM confidence per effect
â”œâ”€â”€ montage_ai.beat_markers           # Pacing markers
â””â”€â”€ notes                             # Human-readable descriptions
```

**Color Grading Example:**
- Applied: "Color Grading preset=teal_orange, intensity=0.9"
- Recommended: "Consider desaturation for dramatic effect"
- Confidence: 0.85

### Roundtrip Workflow

1. **Render:** `./montage-ai.sh run --export` â†’ generates manifest.json + parameters.json
2. **Export:** `./montage-ai.sh export-to-nle` â†’ OTIO/EDL/Premiere/AAF
3. **Import:** Load OTIO in Premiere/Resolve â†’ metadata preserved
4. **Edit:** Adjust parameters, re-export JSON
5. **Re-import:** Load parameters.json back to Montage AI for re-render

---

## ğŸ§ª Tests & CLI

**Status:** âœ… Implemented (Phase 1.5)

### Test Coverage

```bash
# Run OTIO export tests
pytest tests/test_otio_export.py -v

# Test JSON robustness
pytest tests/test_otio_export.py::TestJSONParsingRobustness -v
```

**Test scenarios:**
- âœ… Timeline creation
- âœ… Multi-clip handling
- âœ… Metadata attachment
- âœ… Beat + section markers
- âœ… Multi-format export (OTIO, EDL, Premiere, AAF)
- âœ… JSON parameter serialization
- âœ… Malformed JSON recovery

### CLI Examples

```bash
# Help
./montage-ai.sh export-to-nle --help

# Quick export (default OTIO + EDL)
./montage-ai.sh export-to-nle --manifest /data/output/manifest.json

# All formats with verbose logging
./montage-ai.sh export-to-nle \
  --manifest /data/output/manifest.json \
  --formats otio edl premiere aaf params_json \
  --project-name "Feature Film" \
  --verbose

# Custom FPS/resolution
./montage-ai.sh export-to-nle \
  --manifest /data/output/manifest.json \
  --fps 25.0 \
  --width 3840 --height 2160 \
  --formats premiere
```

---

## ğŸ“‹ Updated Changelog

- **2026-01-09:** 
  - âœ… Export to NLE: OTIO Builder + CLI (`export-to-nle`)
  - âœ… Parser robustness: retry logic + JSON fallback + safe defaults
  - âœ… Tests for OTIO export, JSON parsing
  - âœ… Markdown lint fixes (all docs)

---

## ğŸ¬ Conclusion

Das System ist jetzt **produktionsbereit** fÃ¼r AI-gesteuerte Parameter-Optimierung. Alle Suggester nutzen **zentrale Mechanismen** (CreativeDirector) und sind **cgpu-robust** (auto-fallback zu Ollama).

**Key Achievements:**

1. âœ… **50+ Parameter** zentral definiert und validierbar
2. âœ… **2 Suggester** implementiert (Color Grading, Stabilization)
3. âœ… **cgpu-Integration** robust mit automatischem Fallback
4. âœ… **Zero Fragmentation** - Alle LLM-Calls durch CreativeDirector
5. âœ… **Explainable AI** - LLM liefert Reasoning fÃ¼r Decisions
6. âœ… **Export to NLE** - OTIO/EDL/Premiere/AAF mit vollem Metadata
7. âœ… **CLI Ready** - `./montage-ai.sh export-to-nle` command
8. âœ… **Robust Parser** - Retry logic, JSON extraction fallback, safe defaults

**Next:** Web UI Integration + Cluster validation.

