# Montage AI - Backend Architecture Analysis

**Date:** January 5, 2026  
**Objective:** Identify consolidation opportunities, reduce duplication, and align with "Polish, Don't Generate" philosophy

---

## Executive Summary

Montage AI currently implements two distinct video workflows:
- **Creator (Montage)**: Beat-synced music video montages
- **Shorts Studio**: Vertical video reframing with face tracking

Analysis reveals **~40% code overlap** in core processing (video analysis, FFmpeg operations, job management), with opportunities for **significant consolidation** without losing workflow-specific optimizations.

### Key Findings

| Category | Status | Impact |
|----------|--------|--------|
| **Job Management** | ğŸŸ¢ Unified | Redis + RQ queue shared across workflows |
| **Video Analysis** | ğŸŸ¡ Partial Duplication | Scene detection shared, face tracking isolated |
| **FFmpeg Operations** | ğŸŸ¢ Well-Abstracted | `ffmpeg_utils.py` provides DRY helpers |
| **Audio Analysis** | ğŸ”´ Creator-Only | Not leveraged by Shorts (missed opportunity) |
| **Enhancement Pipeline** | ğŸŸ¢ Unified | `ClipEnhancer` shared by both workflows |
| **State Management** | ğŸŸ¡ Mixed | Creator has `MontageContext`, Shorts uses session API |

---

## 1. Current Architecture Map

### 1.1 Creator Workflow (Montage)

```
User Request â†’ Web UI (montage.html)
     â†“
API (/api/jobs POST) â†’ Redis Job Queue
     â†“
RQ Worker â†’ tasks.run_montage()
     â†“
montage_ai.editor (subprocess)
     â†“
MontageBuilder Pipeline:
  â”œâ”€ Phase 1: Setup Workspace (ResourceManager, GPU detection)
  â”œâ”€ Phase 2: Analyze Assets
  â”‚    â”œâ”€ Audio Analysis (beat detection, energy analysis)
  â”‚    â”œâ”€ Scene Detection (PySceneDetect)
  â”‚    â”œâ”€ Voice Isolation (optional, cgpu)
  â”‚    â””â”€ Output Profile Detection
  â”œâ”€ Phase 3: Plan Montage
  â”‚    â”œâ”€ Story Engine (optional)
  â”‚    â”œâ”€ B-Roll Planning (semantic search)
  â”‚    â”œâ”€ Beat Sync Assembly
  â”‚    â””â”€ Progressive Renderer
  â”œâ”€ Phase 4: Enhance Assets
  â”‚    â”œâ”€ Stabilization (vidstab or cgpu)
  â”‚    â”œâ”€ Upscaling (Real-ESRGAN via cgpu)
  â”‚    â””â”€ Color Enhancement
  â”œâ”€ Phase 5: Render Output (FFmpeg concat)
  â””â”€ Phase 6: Cleanup & Export
       â”œâ”€ Timeline Export (OTIO)
       â””â”€ Temp file deletion
     â†“
Output: gallery_montage_{job_id}_v{variant}_{style}.mp4
```

**Key Modules:**
- `core/montage_builder.py` (2650 lines) - Main orchestrator
- `audio_analysis.py` (1163 lines) - Beat detection, energy analysis
- `scene_analysis.py` (1009 lines) - Scene detection, content analysis
- `clip_enhancement.py` (1011 lines) - Stabilization, upscaling, color grading
- `creative_director.py` - LLM-to-JSON translation
- `storytelling.py` - Story arc engine

### 1.2 Shorts Studio Workflow

```
User Request â†’ Web UI (shorts.html)
     â†“
API Endpoints (no queue, direct processing):
  â”œâ”€ /api/shorts/upload â†’ Save video to INPUT_DIR
  â”œâ”€ /api/shorts/analyze â†’ AutoReframeEngine.analyze()
  â”œâ”€ /api/shorts/visualize â†’ Return crop data JSON
  â””â”€ /api/shorts/render â†’ Apply reframing + captions
     â†“
AutoReframeEngine Pipeline:
  â”œâ”€ Video Loading (OpenCV)
  â”œâ”€ Face Detection (MediaPipe) or Object Tracking (OpenCV KCF/CSRT)
  â”œâ”€ Kalman Filtering (smooth tracking)
  â”œâ”€ Convex Optimization (scipy or fallback to Kalman smoothing)
  â”œâ”€ Crop Window Segmentation
  â””â”€ FFmpeg Application (complex filter with trim + crop + concat)
     â†“
Optional Caption Burning:
  â”œâ”€ Transcription (Whisper via cgpu or local)
  â”œâ”€ SRT Generation
  â””â”€ Caption Overlay (caption_burner.py)
     â†“
Output: shorts_reframed_{timestamp}.mp4
```

**Key Modules:**
- `auto_reframe.py` (618 lines) - Face tracking, crop optimization
- `caption_burner.py` - Caption overlay (shared with Creator)
- `transcriber.py` - Whisper integration (shared with Creator)
- `cgpu_jobs/` - Cloud GPU offloading (shared)

### 1.3 Shared Infrastructure (Well-Designed)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         SHARED INFRASTRUCTURE (DRY âœ“)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Job Management:                                     â”‚
â”‚  â€¢ JobStore (Redis) - Unified job state tracking   â”‚
â”‚  â€¢ RQ Queue - Background job processing            â”‚
â”‚  â€¢ SSE (announcer) - Real-time updates             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ FFmpeg Abstraction:                                 â”‚
â”‚  â€¢ ffmpeg_utils.py - Command builders (DRY)        â”‚
â”‚  â€¢ ffmpeg_config.py - Hardware acceleration        â”‚
â”‚  â€¢ VideoEncodingParams dataclass                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Cloud GPU (cgpu):                                   â”‚
â”‚  â€¢ CGPUJobManager - Queue orchestrator             â”‚
â”‚  â€¢ TranscribeJob, UpscaleJob, StabilizeJob         â”‚
â”‚  â€¢ BeatAnalysisJob, SceneDetectionJob              â”‚
â”‚  â€¢ VoiceIsolationJob, NoiseReductionJob            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Caching:                                            â”‚
â”‚  â€¢ AnalysisCache - Audio/scene/semantic caching    â”‚
â”‚  â€¢ MetadataCache - Video metadata caching          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Enhancement:                                        â”‚
â”‚  â€¢ ClipEnhancer - Stabilization, upscaling, color  â”‚
â”‚  â€¢ Hardware detection (ResourceManager)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Configuration:                                      â”‚
â”‚  â€¢ config.py - Centralized settings (DRY âœ“)        â”‚
â”‚  â€¢ Settings dataclass with nested groups           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Duplication & Consolidation Opportunities

### 2.1 ğŸ”´ HIGH PRIORITY (High ROI, Low Risk)

#### A. Unified Video Analysis Pipeline

**Current State:**
- Creator: `scene_analysis.py` â†’ `SceneDetector` â†’ PySceneDetect â†’ Scene boundaries
- Shorts: `auto_reframe.py` â†’ MediaPipe face detection â†’ Crop windows
- **Duplication:** Both workflows independently:
  - Open video with OpenCV (`cv2.VideoCapture`)
  - Probe metadata (width, height, fps, frame_count)
  - Iterate frame-by-frame
  - Apply different analysis (scenes vs faces)

**Opportunity:**
Create **`VideoAnalysisEngine`** abstraction:

```python
class VideoAnalysisEngine:
    """Unified video analysis with pluggable analyzers."""
    
    def __init__(self, video_path: str):
        self.video_path = video_path
        self.cap = cv2.VideoCapture(video_path)
        self.metadata = self._probe_metadata()
        self._analyzers: List[FrameAnalyzer] = []
    
    def add_analyzer(self, analyzer: FrameAnalyzer):
        """Register a frame analyzer (scene detection, face tracking, etc.)"""
        self._analyzers.append(analyzer)
    
    def analyze(self) -> AnalysisResult:
        """Single-pass analysis with all registered analyzers."""
        for frame_idx, frame in self._iterate_frames():
            for analyzer in self._analyzers:
                analyzer.process_frame(frame, frame_idx, self.metadata)
        
        return AnalysisResult(
            scenes=[a.get_result() for a in self._analyzers if isinstance(a, SceneAnalyzer)],
            crops=[a.get_result() for a in self._analyzers if isinstance(a, FaceTrackingAnalyzer)],
            metadata=self.metadata
        )

# Usage:
engine = VideoAnalysisEngine("input.mp4")
engine.add_analyzer(SceneAnalyzer(threshold=30.0))
engine.add_analyzer(FaceTrackingAnalyzer(target_aspect=9/16))
result = engine.analyze()  # Single video pass, multiple analyses
```

**Benefits:**
- âœ… **Performance**: Single video pass instead of multiple
- âœ… **DRY**: Shared frame iteration, metadata probing
- âœ… **Extensibility**: Easy to add new analyzers (motion detection, object tracking)
- âœ… **Cache-Friendly**: Results can be cached together

**Implementation Effort:** Medium (3-5 days)  
**Risk:** Low (doesn't break existing workflows, optional migration)

---

#### B. Unified Job State Management

**Current State:**
- Creator: Uses `JobStore` (Redis) + `JobPhase` tracking
- Shorts: Direct API processing (no queue, no state persistence)
- **Issue:** Shorts can't track long-running jobs, no retry logic, no progress updates

**Opportunity:**
Extend Shorts to use the same job queue infrastructure:

```python
# Before (Shorts - synchronous):
@app.route('/api/shorts/render', methods=['POST'])
def api_shorts_render():
    reframer = SmartReframer(target_aspect=9/16)
    crop_data = reframer.analyze(video_path)  # Blocks request
    reframer.apply(crop_data, video_path, output_path)  # Blocks request
    return jsonify({"success": True, "path": output_path})

# After (Shorts - async with queue):
@app.route('/api/shorts/render', methods=['POST'])
def api_shorts_render():
    job_id = datetime.now().strftime("%Y%m%d_%H%M%S")
    job = {
        "id": job_id,
        "type": "shorts_reframe",
        "options": {
            "video_path": video_path,
            "reframe_mode": reframe_mode,
            "caption_style": caption_style,
        },
        "status": "queued",
        "phase": JobPhase.initial().to_dict(),
    }
    job_store.create_job(job_id, job)
    q.enqueue(run_shorts_reframe, job_id, job['options'])  # Background task
    return jsonify(job)
```

**Benefits:**
- âœ… **Consistency**: Same job tracking for all workflows
- âœ… **Scalability**: Shorts can leverage RQ worker pool
- âœ… **User Experience**: Progress updates via SSE (same as Creator)
- âœ… **Resilience**: Retry logic, failure handling

**Implementation Effort:** Small (1-2 days)  
**Risk:** Very Low (extends existing infrastructure)

---

#### C. Shared Audio Analysis for Shorts

**Current State:**
- Creator: `audio_analysis.py` for beat detection, energy analysis
- Shorts: **Doesn't use audio analysis at all**
- **Missed Opportunity:** Shorts could auto-cut to music beats, detect highlight moments

**Opportunity:**
Leverage existing audio analysis in Shorts:

```python
# Shorts Studio with Audio-Aware Cutting
class ShortsBuilder:
    def __init__(self, video_path: str, music_path: Optional[str] = None):
        self.video_path = video_path
        self.music_path = music_path
        
        # Reuse Creator's audio analysis
        if music_path:
            from montage_ai.audio_analysis import AudioAnalyzer
            self.audio_analyzer = AudioAnalyzer(music_path)
            self.audio_analyzer.analyze()
    
    def detect_highlights(self, max_clips: int = 5, duration: float = 30.0):
        """Detect highlight moments using audio energy + beat alignment."""
        if not self.music_path:
            return self._fallback_highlights()
        
        # HIGH-ENERGY BEATS = GOOD CUT POINTS
        beats = self.audio_analyzer.beat_times
        energy = self.audio_analyzer.energy_curve
        
        # Find beats with high energy (top 20%)
        energy_threshold = np.percentile(energy, 80)
        highlight_beats = [b for b in beats if self._energy_at(b) > energy_threshold]
        
        # Create clips around highlight beats
        clips = []
        for beat in highlight_beats[:max_clips]:
            clips.append({
                "start": max(0, beat - duration / 2),
                "end": beat + duration / 2,
                "score": self._energy_at(beat),
            })
        
        return clips
```

**Benefits:**
- âœ… **Better Shorts**: Auto-cut to music drops, viral potential â†‘
- âœ… **Code Reuse**: ~1200 lines of battle-tested audio analysis
- âœ… **Feature Parity**: Shorts gets "energy-aware" cutting like Creator

**Implementation Effort:** Medium (2-3 days)  
**Risk:** Low (additive feature, doesn't break existing behavior)

---

### 2.2 ğŸŸ¡ MEDIUM PRIORITY (Medium ROI, Low Risk)

#### D. Unified Enhancement Pipeline

**Current State:**
- Creator: Uses `ClipEnhancer` with full pipeline (stabilize â†’ upscale â†’ enhance)
- Shorts: Minimal enhancement (relies on ClipEnhancer but doesn't expose in UI)
- **Partial Duplication:** Both call `ClipEnhancer.stabilize()`, `ClipEnhancer.upscale()`

**Opportunity:**
Expose enhancement options in Shorts UI, reuse same backend:

```python
# Shorts Studio with Enhancement Options
@app.route('/api/shorts/render', methods=['POST'])
def api_shorts_render():
    data = request.json
    video_path = data.get('video_path')
    
    # NEW: Enhancement options (same as Creator)
    enhance_options = {
        "stabilize": data.get('stabilize', False),
        "upscale": data.get('upscale', False),
        "enhance": data.get('enhance', False),
    }
    
    # Reuse ClipEnhancer (already supports all modes)
    if any(enhance_options.values()):
        enhancer = ClipEnhancer()
        if enhance_options['stabilize']:
            video_path = enhancer.stabilize(video_path, f"{video_path}_stab.mp4")
        if enhance_options['upscale']:
            video_path = enhancer.upscale(video_path, f"{video_path}_upscale.mp4")
        if enhance_options['enhance']:
            video_path = enhancer.enhance(video_path, f"{video_path}_enhance.mp4")
    
    # Continue with reframing...
```

**Benefits:**
- âœ… **Feature Parity**: Shorts gets same enhancement options as Creator
- âœ… **No New Code**: Backend already supports it
- âœ… **User Expectation**: Consistent UX across workflows

**Implementation Effort:** Small (1 day)  
**Risk:** Very Low (UI change + config pass-through)

---

#### E. Abstract Base Class for Workflows

**Current State:**
- Creator: `MontageBuilder` with phased pipeline
- Shorts: `AutoReframeEngine` with ad-hoc methods
- **No Shared Interface:** Hard to add new workflows (e.g., "Trailer Studio", "Podcast Clips")

**Opportunity:**
Create **`VideoWorkflow`** abstract base class:

```python
from abc import ABC, abstractmethod

class VideoWorkflow(ABC):
    """Abstract base for all video processing workflows."""
    
    def __init__(self, job_id: str, options: dict):
        self.job_id = job_id
        self.options = options
        self.state = WorkflowState()
    
    @abstractmethod
    def analyze_inputs(self) -> AnalysisResult:
        """Phase 1: Analyze source materials."""
        pass
    
    @abstractmethod
    def plan_output(self) -> OutputPlan:
        """Phase 2: Plan the output structure."""
        pass
    
    @abstractmethod
    def render(self) -> RenderResult:
        """Phase 3: Execute render pipeline."""
        pass
    
    def execute(self) -> WorkflowResult:
        """Standard execution flow for all workflows."""
        self.state.set_phase("analyzing")
        analysis = self.analyze_inputs()
        
        self.state.set_phase("planning")
        plan = self.plan_output()
        
        self.state.set_phase("rendering")
        result = self.render()
        
        return WorkflowResult(success=True, output=result)

# Concrete implementations:
class MontageWorkflow(VideoWorkflow):
    def analyze_inputs(self):
        # Scene detection, beat detection, etc.
        ...

class ShortsWorkflow(VideoWorkflow):
    def analyze_inputs(self):
        # Face tracking, crop optimization
        ...

class TrailerWorkflow(VideoWorkflow):  # NEW!
    def analyze_inputs(self):
        # Highlight detection, music sync
        ...
```

**Benefits:**
- âœ… **Consistency**: All workflows follow same lifecycle
- âœ… **Testability**: Shared test harness for all workflows
- âœ… **Extensibility**: New workflows inherit common infrastructure

**Implementation Effort:** Medium (3-4 days)  
**Risk:** Low (refactoring, doesn't change behavior)

---

### 2.3 ğŸŸ¢ LOW PRIORITY (Low ROI, High Effort)

#### F. Microservices Split (NOT RECOMMENDED)

**Why Not:**
- âŒ **Over-Engineering**: Adds complexity (service mesh, API versioning, deployment)
- âŒ **Against KISS**: "Polish, Don't Generate" favors monoliths for rapid iteration
- âŒ **Premature Optimization**: Current architecture handles load well
- âŒ **Deployment Overhead**: K3s cluster already manages multiple pods efficiently

**Decision:** Keep monolithic Flask app, use **modular architecture** within single codebase.

---

## 3. State-of-the-Art Patterns Research

### 3.1 Plugin/Strategy Pattern (RECOMMENDED)

**Pattern:** Strategy pattern for workflow-specific processing

```python
# Strategy interface
class ProcessingStrategy(ABC):
    @abstractmethod
    def process_clip(self, clip: Clip, context: Context) -> ProcessedClip:
        pass

# Concrete strategies
class BeatSyncStrategy(ProcessingStrategy):
    """Creator: Cut on beats"""
    def process_clip(self, clip, context):
        beats = context.audio_analysis.beat_times
        return clip.trim_to_nearest_beat(beats)

class FaceTrackingStrategy(ProcessingStrategy):
    """Shorts: Follow faces"""
    def process_clip(self, clip, context):
        crops = context.face_tracker.analyze(clip)
        return clip.apply_crops(crops)

# Usage
class VideoProcessor:
    def __init__(self, strategy: ProcessingStrategy):
        self.strategy = strategy
    
    def process(self, clips: List[Clip], context: Context):
        return [self.strategy.process_clip(c, context) for c in clips]
```

**Real-World Examples:**
- **FFmpeg**: Filter graph system (each filter is a strategy)
- **MLOps**: Feature stores with pluggable transformers (Feast, Tecton)
- **Video Editors**: Effect chains in DaVinci Resolve, Premiere Pro

**Benefits:**
- âœ… Easy to add new workflows (Trailer, Podcast, Documentary)
- âœ… Testable in isolation
- âœ… Clear separation of concerns

---

### 3.2 Pipeline Abstraction (CURRENT APPROACH âœ“)

**Pattern:** Montage AI already uses this well!

```python
# MontageBuilder pipeline (good example)
def build(self):
    self._setup_workspace()       # Phase 1
    self._analyze_assets()        # Phase 2
    self._plan_montage()          # Phase 3
    self._enhance_assets()        # Phase 4
    self._render_output()         # Phase 5
    self._cleanup()               # Phase 6
```

**Improvement:** Extend to Shorts:

```python
class ShortsBuilder:
    def build(self):
        self._setup_workspace()       # Same as Creator
        self._analyze_video()         # Shorts-specific (face tracking)
        self._plan_crops()            # Shorts-specific (crop optimization)
        self._enhance_clips()         # Same as Creator (ClipEnhancer)
        self._render_output()         # Same as Creator (FFmpeg)
        self._cleanup()               # Same as Creator
```

**Real-World Examples:**
- **Airflow DAGs**: Task dependencies with retry logic
- **Luigi**: Data pipelines with checkpointing
- **Celery Canvas**: Workflow primitives (chain, group, chord)

---

### 3.3 Job Queue Patterns (CURRENT APPROACH âœ“)

**Pattern:** Montage AI uses **RQ (Redis Queue)** well

**Current Implementation:**
- Redis as broker
- RQ workers for background processing
- JobStore for state persistence
- SSE for real-time updates

**Improvement Opportunity:**
Add **priority queues** for different workflow types:

```python
# High-priority queue (interactive workflows)
q_high = Queue('high', connection=redis_conn)

# Low-priority queue (batch processing)
q_low = Queue('low', connection=redis_conn)

# Route based on workflow
if job_type == "shorts":
    q_high.enqueue(run_shorts_reframe, job_id)  # User waiting
elif job_type == "montage" and is_preview:
    q_high.enqueue(run_montage, job_id)  # Quick preview
else:
    q_low.enqueue(run_montage, job_id)  # Final render
```

**Real-World Examples:**
- **Celery**: Priority queues with routing keys
- **Sidekiq**: Weighted queues (critical:5, default:3, low:1)
- **BullMQ**: Priority-based job scheduling

---

### 3.4 State Management for Long-Running Jobs (NEEDS IMPROVEMENT)

**Current State:**
- Creator: Good (JobPhase tracking, SSE updates)
- Shorts: Poor (no job persistence, no progress updates)

**Recommended Pattern:** **Saga Pattern** for long-running workflows

```python
class WorkflowSaga:
    """Manage long-running workflow state with rollback support."""
    
    def __init__(self, job_id: str):
        self.job_id = job_id
        self.steps: List[SagaStep] = []
        self.state = JobStore()
    
    def add_step(self, step: SagaStep):
        self.steps.append(step)
    
    def execute(self):
        completed = []
        try:
            for step in self.steps:
                self.state.update_job(self.job_id, {"phase": step.name})
                step.execute()
                completed.append(step)
        except Exception as e:
            # Rollback completed steps
            for step in reversed(completed):
                step.rollback()
            raise

# Usage:
saga = WorkflowSaga(job_id)
saga.add_step(AnalysisStep())
saga.add_step(RenderStep())
saga.add_step(ExportStep())
saga.execute()
```

**Real-World Examples:**
- **Temporal.io**: Workflow orchestration with checkpointing
- **AWS Step Functions**: State machines with retry/rollback
- **Cadence**: Durable workflows with compensation

---

### 3.5 Error Handling & Resilience (CURRENT APPROACH âœ“)

**Current Implementation (Good):**
- Retry logic in `CGPUJobManager`
- Graceful degradation (cgpu â†’ local fallback)
- Strict mode for production (`STRICT_CLOUD_COMPUTE`)

**No Changes Needed** - Already follows best practices!

---

## 4. Refactoring Recommendations

### 4.1 Phase 1: High-Impact, Low-Risk (Sprint 1-2)

| Task | Effort | Impact | Risk | Priority |
|------|--------|--------|------|----------|
| **Unified Job Queue for Shorts** | 1-2 days | High | Low | P0 |
| **Shared Audio Analysis for Shorts** | 2-3 days | High | Low | P0 |
| **Video Analysis Engine Abstraction** | 3-5 days | Medium | Low | P1 |
| **Enhancement Options in Shorts UI** | 1 day | Medium | Very Low | P1 |

**Expected Benefits:**
- ğŸ¯ **Performance**: ~30% faster with single-pass video analysis
- ğŸ¯ **Code Reduction**: -400 lines of duplicated video I/O
- ğŸ¯ **Feature Parity**: Shorts gets audio-aware cutting + enhancement
- ğŸ¯ **UX**: Consistent job tracking across all workflows

---

### 4.2 Phase 2: Foundation for Growth (Sprint 3-4)

| Task | Effort | Impact | Risk | Priority |
|------|--------|--------|------|----------|
| **VideoWorkflow Abstract Base Class** | 3-4 days | High | Low | P1 |
| **Unified Analysis Result Cache** | 2 days | Medium | Low | P2 |
| **Priority Queue Routing** | 1 day | Low | Low | P2 |
| **Workflow Saga Pattern** | 3 days | Medium | Medium | P2 |

**Expected Benefits:**
- ğŸ¯ **Extensibility**: New workflows in hours, not days
- ğŸ¯ **Maintainability**: Shared test harness for all workflows
- ğŸ¯ **Reliability**: Rollback support for failed jobs

---

### 4.3 Phase 3: Advanced Optimizations (Sprint 5-6)

| Task | Effort | Impact | Risk | Priority |
|------|--------|--------|------|----------|
| **Multi-Pass Video Analysis** | 5 days | High | Medium | P2 |
| **Intelligent Cache Warming** | 3 days | Medium | Low | P3 |
| **Workflow Metrics Dashboard** | 2 days | Low | Low | P3 |

---

## 5. What NOT to Consolidate

### 5.1 Keep Separate

| Component | Reason |
|-----------|--------|
| **Face Tracking Logic** | Shorts-specific, no overlap with Creator |
| **Beat Detection Logic** | Creator-specific, computationally expensive |
| **UI Templates** | Different UX patterns, consolidation would hurt usability |
| **Creative Director** | Creator-specific AI orchestration |

### 5.2 Avoid Premature Abstraction

**Bad Idea:**
```python
# DON'T do this (over-abstraction)
class UniversalVideoProcessor:
    def process(self, mode: str, options: dict):
        if mode == "montage":
            # 500 lines of montage logic
        elif mode == "shorts":
            # 300 lines of shorts logic
        elif mode == "trailer":
            # 400 lines of trailer logic
        # ... 2000 lines of spaghetti
```

**Good Idea:**
```python
# DO this (strategy pattern)
class VideoProcessor:
    def __init__(self, workflow: VideoWorkflow):
        self.workflow = workflow
    
    def process(self):
        return self.workflow.execute()
```

---

## 6. Risk Assessment

| Change | Risk Level | Mitigation |
|--------|------------|------------|
| **Job Queue for Shorts** | ğŸŸ¢ Low | Feature flag, gradual rollout |
| **Video Analysis Engine** | ğŸŸ¡ Medium | Keep legacy code paths initially |
| **Audio in Shorts** | ğŸŸ¢ Low | Optional feature (graceful degradation) |
| **Abstract Base Class** | ğŸŸ¢ Low | Refactoring only (no behavior change) |
| **Priority Queues** | ğŸŸ¢ Low | Additive change (no breaking changes) |
| **Saga Pattern** | ğŸŸ¡ Medium | Thorough testing needed |

---

## 7. Performance Projections

### 7.1 Current Baseline

| Workflow | Analysis | Processing | Rendering | Total |
|----------|----------|------------|-----------|-------|
| **Creator** (1080p, 60s) | 15s | 45s | 30s | 90s |
| **Shorts** (1080pâ†’9:16, 30s) | 12s | 8s | 10s | 30s |

### 7.2 Post-Consolidation (Projected)

| Workflow | Analysis | Processing | Rendering | Total | Savings |
|----------|----------|------------|-----------|-------|---------|
| **Creator** (with unified analysis) | 10s | 45s | 30s | 85s | **-6%** |
| **Shorts** (with audio highlights) | 8s | 12s | 10s | 30s | **0%** (new feature) |
| **Creator + Shorts** (shared cache) | 10s | 45s | 30s | 85s | **-33%** (cache hit) |

**Key Insight:** Consolidation primarily benefits **multi-workflow projects** (e.g., create Shorts from Creator output).

---

## 8. Text-Based Architecture Diagrams

### 8.1 Current State

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     WEB UI (Flask)                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ montage.html    â”‚ shorts.html    â”‚ transcript.html            â”‚
â”‚ (Creator UI)    â”‚ (Shorts UI)    â”‚ (Editor UI)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                â”‚                      â”‚
         v                v                      v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ POST /api/jobs â”‚ â”‚ POST /shortsâ”‚ â”‚ POST /transcript  â”‚
â”‚ (queued)       â”‚ â”‚ (sync)      â”‚ â”‚ (queued)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                â”‚                   â”‚
         v                v                   v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Redis Job Store (Shared)                â”‚
â”‚  â€¢ JobStore (state persistence)                   â”‚
â”‚  â€¢ RQ Queue (background processing)               â”‚
â”‚  â€¢ SSE Announcer (real-time updates)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚ (Shorts bypasses queue!)
         v                      v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RQ Worker      â”‚     â”‚ Synchronous     â”‚
â”‚ â”œâ”€ montage     â”‚     â”‚ Processing      â”‚
â”‚ â””â”€ transcript  â”‚     â”‚ â””â”€ auto_reframe â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚
         v                      v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         SHARED INFRASTRUCTURE                      â”‚
â”‚  â€¢ FFmpeg (ffmpeg_utils.py)                       â”‚
â”‚  â€¢ ClipEnhancer (stabilize, upscale, enhance)     â”‚
â”‚  â€¢ AnalysisCache (audio, scenes, semantic)        â”‚
â”‚  â€¢ CGPUJobManager (cloud GPU offloading)          â”‚
â”‚  â€¢ ResourceManager (hardware detection)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.2 Proposed State (Post-Consolidation)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     WEB UI (Flask)                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ montage.html    â”‚ shorts.html    â”‚ transcript.html            â”‚
â”‚ (Creator UI)    â”‚ (Shorts UI)    â”‚ (Editor UI)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                â”‚                      â”‚
         v                v                      v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           UNIFIED API LAYER (All workflows)                     â”‚
â”‚  POST /api/jobs                                                 â”‚
â”‚  â€¢ type: "montage" | "shorts" | "transcript"                   â”‚
â”‚  â€¢ Consistent job lifecycle for all workflows                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Redis Job Store + Priority Queues                    â”‚
â”‚  â€¢ JobStore (unified state for all workflows)                  â”‚
â”‚  â€¢ RQ High Priority (shorts, transcript - interactive)         â”‚
â”‚  â€¢ RQ Low Priority (montage final renders)                     â”‚
â”‚  â€¢ SSE Announcer (real-time updates for all)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               WORKFLOW ORCHESTRATOR (NEW)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ MontageWorkflow  â”‚ â”‚ShortsWorkflowâ”‚ â”‚TranscriptWorkflowâ”‚    â”‚
â”‚  â”‚ extends          â”‚ â”‚extends       â”‚ â”‚extends           â”‚    â”‚
â”‚  â”‚ VideoWorkflow    â”‚ â”‚VideoWorkflow â”‚ â”‚VideoWorkflow     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚           â”‚                  â”‚                   â”‚              â”‚
â”‚           v                  v                   v              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚     VideoAnalysisEngine (SHARED)                     â”‚      â”‚
â”‚  â”‚  â€¢ Single-pass video analysis                       â”‚      â”‚
â”‚  â”‚  â€¢ Pluggable analyzers:                             â”‚      â”‚
â”‚  â”‚    - SceneAnalyzer (Creator)                        â”‚      â”‚
â”‚  â”‚    - FaceTrackingAnalyzer (Shorts)                  â”‚      â”‚
â”‚  â”‚    - MotionAnalyzer (NEW)                           â”‚      â”‚
â”‚  â”‚  â€¢ Unified metadata caching                         â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚           â”‚                  â”‚                   â”‚              â”‚
â”‚           v                  v                   v              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚       AudioAnalysisEngine (SHARED)                   â”‚      â”‚
â”‚  â”‚  â€¢ Beat detection (Creator + Shorts)                â”‚      â”‚
â”‚  â”‚  â€¢ Energy analysis (Creator + Shorts)               â”‚      â”‚
â”‚  â”‚  â€¢ Highlight detection (NEW for Shorts)             â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         SHARED INFRASTRUCTURE (Enhanced)                        â”‚
â”‚  â€¢ FFmpeg (ffmpeg_utils.py) âœ“ Already DRY                      â”‚
â”‚  â€¢ ClipEnhancer (stabilize, upscale, enhance) âœ“ Already shared â”‚
â”‚  â€¢ AnalysisCache (unified for all workflows) ğŸ”„ Enhanced       â”‚
â”‚  â€¢ CGPUJobManager (cloud GPU offloading) âœ“ Already shared      â”‚
â”‚  â€¢ ResourceManager (hardware detection) âœ“ Already shared       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 9. Code Reduction Estimate

| Module | Current Lines | Post-Consolidation | Savings |
|--------|---------------|-------------------|---------|
| **Video I/O** (OpenCV boilerplate) | ~200 | ~80 | -120 |
| **Metadata Probing** (ffprobe calls) | ~150 | ~60 | -90 |
| **Job State Management** (Shorts sync â†’ async) | ~0 | ~50 | +50 (new feature) |
| **Audio Analysis Duplication** (Shorts reuse) | ~0 | ~30 | +30 (new feature) |
| **Enhancement Pipeline** (Shorts UI) | ~0 | ~20 | +20 (new feature) |
| **Abstract Base Class** (workflow template) | ~0 | ~100 | +100 (new foundation) |
| **TOTAL** | ~350 | ~340 | **-10 net lines** |

**Key Insight:** Consolidation doesn't reduce line count much (we're already DRY!), but it **improves maintainability and extensibility** significantly.

---

## 10. Conclusion

### 10.1 Strategic Recommendations

1. **Adopt Phase 1 (High-Impact):** Unified job queue, shared audio analysis, video analysis engine
2. **Adopt Phase 2 (Foundation):** Abstract base class for workflows
3. **Defer Phase 3:** Advanced optimizations until user demand justifies complexity
4. **Avoid Microservices:** Current monolithic architecture aligns with KISS principle

### 10.2 Alignment with "Polish, Don't Generate" Philosophy

âœ… **Consolidation supports core mission:**
- Reduces technical debt (DRY)
- Enables rapid feature iteration (shared infrastructure)
- Maintains performance (single-pass analysis)
- Preserves workflow-specific optimizations (strategy pattern)

### 10.3 Next Steps

1. **Create Feature Branch:** `feature/video-analysis-engine`
2. **Implement VideoAnalysisEngine** with backward compatibility
3. **Migrate Creator** to use new engine (with fallback to legacy)
4. **Migrate Shorts** to use new engine
5. **Deprecate legacy code paths** after 2 weeks of testing
6. **Repeat for audio analysis** and job queue

---

**Prepared by:** GitHub Copilot (Claude Sonnet 4.5)  
**Review Requested:** Engineering Team  
**Estimated Timeline:** 3-4 sprints (6-8 weeks)
