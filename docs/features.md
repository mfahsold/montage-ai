# Features

> **Philosophy:** We do not generate pixels. We polish them.

Complete guide to Montage AI capabilities.

---

## ðŸ†• 2026 Releases

### v1.1 Enhancement Suite (January 2026)

Professional video enhancement with full NLE compatibility.

#### AI Denoising

Reduce noise while preserving film grain texture.

**Methods:**
- **hqdn3d:** Fast temporal/spatial denoising (default)
- **nlmeans:** High-quality non-local means (slower, better)

**Parameters:**
| Parameter | Range | Default | Description |
|-----------|-------|---------|-------------|
| `temporal_strength` | 0.0-1.0 | 0.5 | Cross-frame reduction |
| `spatial_strength` | 0.0-1.0 | 0.3 | In-frame reduction |
| `chroma_strength` | 0.0-1.0 | 0.5 | Color noise reduction |
| `preserve_grain` | 0.0-1.0 | 0.2 | Keep film texture |

**Usage:**
```bash
./montage-ai.sh run hitchcock --denoise
# Or with custom settings
DENOISE_SPATIAL=0.4 DENOISE_TEMPORAL=0.6 ./montage-ai.sh run
```

#### Film Grain Simulation

Add authentic film grain for cinematic look.

**Presets:**
| Type | Character | Use Case |
|------|-----------|----------|
| `fine` | Subtle texture | Modern digital |
| `medium` | Visible grain | Music videos |
| `35mm` | Classic cinema | Feature films |
| `16mm` | Documentary | Indie, documentary |
| `8mm` | Vintage home movie | Retro aesthetics |

**Usage:**
```bash
./montage-ai.sh run --film-grain 35mm
```

#### Dialogue Ducking

Auto-detect speech and lower background music.

**How it works:**
1. VAD (Voice Activity Detection) finds speech segments
2. Generates volume keyframes with attack/release curves
3. Exports NLE-compatible automation

**Detection Methods:**
| Method | Quality | Speed | Requirements |
|--------|---------|-------|--------------|
| Silero | Excellent | Medium | torch |
| WebRTC | Good | Fast | webrtcvad |
| FFmpeg | Basic | Fast | Built-in |

**Parameters:**
| Setting | Default | Description |
|---------|---------|-------------|
| `duck_level_db` | -12 | Volume reduction |
| `attack_time` | 0.15s | Ramp down time |
| `release_time` | 0.30s | Ramp up time |

**Export:** CSV, DaVinci Resolve text, Premiere XML

#### Enhancement Tracking & NLE Export

Every AI decision is tracked and exportable.

**What's tracked:**
- Stabilization (method, smoothing, crop mode)
- Upscaling (model, scale factor)
- Denoising (spatial/temporal strength)
- Sharpening (amount, radius)
- Color grading (preset, intensity, LUT)
- Color matching (reference clip, method)
- Film grain (type, intensity)
- Dialogue ducking (keyframes, segments)

**Export formats:**
- **OTIO metadata:** Full parameters in clip metadata
- **EDL comments:** `* MONTAGE_AI DENOISE: spatial=0.3`
- **Recipe cards:** Human-readable Markdown instructions

**Recipe Card Example:**
```markdown
## Clip: DJI_0042.MP4
### DaVinci Resolve Recreation:
1. **Stabilizer** (Color Page > Tracker)
   - Mode: Perspective
   - Smoothing: 0.30
2. **Noise Reduction** (Color Page > Spatial NR)
   - Luma Threshold: 3.0
3. **Color Wheels** (Color Page > Primary)
   - Saturation: 115%
```

---

### Story Engine (Narrative Arc)

AI-driven 5-phase narrative structure for cinematic storytelling.

**Story Arc Phases:**
| Phase | Position | Energy | Purpose |
|-------|----------|--------|---------|
| Intro | 0-15% | Low-Medium | Establish context |
| Build | 15-40% | Rising | Develop tension |
| Climax | 40-70% | High | Peak intensity |
| Sustain | 70-90% | High-Medium | Maintain engagement |
| Outro | 90-100% | Descending | Resolution |

**Arc Presets:**
- **hero_journey:** Classic narrative arc
- **mtv_energy:** Peak early, sustain high
- **documentary:** Gradual reveal, observational
- **thriller:** Slow build, explosive release
- **flat:** Consistent energy throughout

**How it works:**
1. Analyzes all clips for visual tension (motion, faces, objects)
2. Maps clips to story phases based on energy fit
3. Uses CSP solver for optimal clip placement
4. Ensures narrative coherence across the timeline

**Usage:**
```bash
./montage-ai.sh run hitchcock --story-engine --story-arc thriller
```

---

### Transcript Editor

Edit video by removing text. AI handles the cuts.

**Workflow:**
1. Upload video â†’ Auto-transcribe (Whisper)
2. View transcript with word-level timestamps
3. Delete words to remove segments
4. Rearrange to reorder scenes
5. Export video or OTIO timeline

**Capabilities:**
- **Live Preview:** 360p preview updates 2 seconds after edits
- **Word-Level Sync:** Click any word to seek
- **Filler Detection:** Highlights "um", "uh", "like" for removal
- **Silence Removal:** Auto-gap detection
- **Export:** MP4, EDL (Premiere), OTIO (Resolve)

**Access:** Web UI at `/transcript`

---

### Pro Handoff (Timeline Export)

Move from Montage AI to professional NLEs (DaVinci, Premiere, Resolve).

**Formats:**
- **OTIO (.otio):** Native for Resolve, Premiere, Nuke
- **FCP XML (.xml):** Universal standard
- **EDL (.edl):** Legacy fallback

**Features:**
- Source relinking to original high-res files
- **Smart Proxies:** H.264 (SOTA optimized for scrubbing), ProRes, DNxHR
- Conform guide with step-by-step instructions
- Seamless roundtrip via OTIO

---

### Shorts Studio

Auto-reframe to 9:16 for TikTok, Instagram, YouTube Shorts.

**Preview:**
- Live 9:16 phone frame
- Safe zone overlays (title, action, platform UI)
- Platform guides (TikTok, Instagram, YouTube)

**Tracking Modes:**
- **Auto:** AI detects and follows subject
- **Face:** Face detection for talking heads
- **Center:** Simple center crop
- **Custom:** Manual keyframes

**Smart Features:**
- **Cinema Path:** Convex optimization for fluid camera motion
- **Subject Safety:** Keeps subjects in golden zone
- **Voice Isolation:** Demucs for clean dialogue (denoising)
- **Captions:** TikTok, Minimal, Bold, Karaoke styles
- **Highlights:** Auto-detect best moments by energy/motion/faces

**Access:** Web UI at `/shorts`

---

### Quality Profiles

One selection replaces multiple toggles. Choose based on your goal, not technical details.

| Profile | Resolution | Enhancements | Use Case |
|---------|------------|--------------|----------|
| ðŸš€ **Preview** | 360p | None | Fast iteration (Ultrafast preset) |
| ðŸ“º **Standard** | 1080p | Color grading | Social media, general use |
| âœ¨ **High** | 1080p | Grading + stabilization | Professional delivery |
| ðŸŽ¬ **Master** | 4K | All + AI upscaling | Broadcast, cinema, archival |

**What each profile enables:**

```
Preview:   enhance=false, stabilize=false, upscale=false, resolution=360p, preset=ultrafast
Standard:  enhance=true,  stabilize=false, upscale=false, resolution=1080p
High:      enhance=true,  stabilize=true,  upscale=false, resolution=1080p
Master:    enhance=true,  stabilize=true,  upscale=true,  resolution=4k
```

**Usage:**
```bash
# CLI
./montage-ai.sh preview hitchcock   # Fast 360p render
./montage-ai.sh finalize hitchcock  # Upgrade to High Quality
./montage-ai.sh run hitchcock --quality high

# Environment variable
QUALITY_PROFILE=master ./montage-ai.sh run

# Web UI: Select from Quality Profile cards
```

### Preview-First Workflow

Iterate faster by separating creative decisions from rendering time.

1.  **Auto-Preview:** Upload clips and get a 360p rough cut in seconds.
2.  **Review:** Check pacing, music sync, and story arc immediately.
3.  **Finalize:** Click "Finalize (1080p)" to render the master copy with full stabilization and enhancement.

---

### Cloud Acceleration

Single toggle for all cloud GPU features with graceful local fallback.

**What it enables:**
- AI upscaling via cloud GPU (Real-ESRGAN on H100/A100)
- Fast transcription (Whisper large model)
- LLM creative direction (Gemini Pro)

**Fallback behavior:**
```
Cloud available?  â†’ Use cloud GPU
Cloud unavailable â†’ Fall back to local processing
Local GPU?        â†’ Use Vulkan acceleration  
CPU only?         â†’ Use optimized CPU path
```

**Privacy guarantee:** Only enabled features use cloud. Raw footage stays local unless upscaling is enabled.

**Usage:**
```bash
# CLI
CLOUD_ACCELERATION=true ./montage-ai.sh run --upscale

# Web UI: Toggle "Cloud Acceleration" switch
```

---

## Timeline Export (Pro Handoff) {#timeline-export}

Export your AI rough cut to professional NLEs for finishing.

**Supported formats:**
- **OTIO** â€” OpenTimelineIO, preferred for modern NLEs
- **EDL** â€” Edit Decision List, legacy support
- **CSV** â€” Spreadsheet review, logging
- **JSON** â€” Metadata, automation

**Usage:**
```bash
./montage-ai.sh run hitchcock --export-timeline --generate-proxies
```

**Outputs in `data/output/`:**
- `montage.otio` â€” Timeline file
- `montage.edl` â€” Legacy EDL
- `montage.csv` â€” Cut log
- `montage_metadata.json` â€” Full metadata
- `proxies/` â€” Optional low-res clips for offline editing

**NLE Import:**
| NLE | Recommended Format | Notes |
|-----|-------------------|-------|
| DaVinci Resolve | OTIO | File â†’ Import â†’ Timeline |
| Premiere Pro | OTIO or EDL | May need media relink |
| Final Cut Pro | OTIO | Via third-party plugin |
| Avid Media Composer | EDL | Relink originals |

---

## Core Editing

- Beat-synced cuts using `librosa` beat detection
- Style-aware pacing, transitions, and color looks
- Story arc shaping (intro â†’ build â†’ climax â†’ outro)
- LLM-powered "Creative Director" (Ollama local or Gemini via cgpu)
- **Agentic Creative Loop** for iterative quality refinement

## Style Templates (Built-in)

| Style          | Best for                 | Traits                                      |
| -------------- | ------------------------ | ------------------------------------------- |
| `dynamic`      | General purpose          | Adapts to music energy                      |
| `hitchcock`    | Thrillers, reveals       | Slow build, explosive climax, high contrast |
| `mtv`          | Music videos, dance      | 1-2 beat cuts, vibrant, hard cuts only      |
| `action`       | Sports, adventure        | Fast pacing, motion preference              |
| `documentary`  | Travel, interviews       | Natural pacing, mixed transitions           |
| `minimalist`   | Art house, meditation    | Very slow, desaturated, long takes          |
| `wes_anderson` | Quirky, aesthetic pieces | Symmetry bias, warm pastel look             |

### Custom Styles (JSON)

Place JSON in `src/montage_ai/styles/` or point to it:

```bash
STYLE_PRESET_PATH=/path/to/my_style.json ./montage-ai.sh run my_style
# or whole directory
STYLE_PRESET_DIR=/path/to/styles ./montage-ai.sh run my_style
```

Minimal schema:

```json
{
  "id": "my_style",
  "description": "Energetic vlog",
  "params": {
    "pacing": {"speed": "fast", "variation": "moderate"},
    "transitions": {"type": "hard_cuts"},
    "effects": {"color_grading": "vibrant", "stabilization": false}
  }
}
```

## Web UI (Fastest path)

```bash
make web              # or: docker compose -f docker-compose.web.yml up
# open http://localhost:5001
```


Flow: upload videos + music â†’ pick style or prompt â†’ toggle enhance/stabilize/upscale/cloud GPU â†’ Create Montage â†’ download MP4 (and timeline if enabled).

Useful endpoints (for automation):

- `GET /api/status` â€“ health
- `GET /api/files` â€“ list uploads
- `POST /api/upload` (multipart, fields: `file`, `type=video|music`)
- `POST /api/jobs` â€“ create job with JSON body (`style`, `prompt`, `stabilize`, `upscale`, `cgpu`, `export_timeline`, ...)
- `GET /api/jobs/{id}` â€“ job status
- `GET /api/download/{filename}` â€“ download outputs

## Responsible AI & Transparency

- **Local-first processing** with opt-in cloud GPU/LLM
- **No training on user footage**
- **Decision logs** available via `EXPORT_DECISIONS=true`
- **Transparency payload** at `GET /api/transparency`

See [responsible_ai.md](responsible_ai.md) for the full policy.

## Timeline Export (OTIO/EDL)

Enable during run:

```bash
./montage-ai.sh run hitchcock --export-timeline --generate-proxies
```

Outputs in `data/output/`:
- `*.otio` (preferred), `*.edl`, `*.csv`, metadata JSON, optional proxies folder.


Import tips:
- **DaVinci Resolve:** File â†’ Import â†’ Timeline â†’ select `.otio`; relink media if paths differ.
- **Premiere Pro / Avid:** use `.edl` and relink originals.

## Cloud LLM & GPU (cgpu)

- Install: `npm i -g cgpu` (plus gemini-cli; run `cgpu connect` once)
- Enable Gemini LLM: `CGPU_ENABLED=true ./montage-ai.sh run --cgpu`
- Enable Colab GPU upscaling: `CGPU_GPU_ENABLED=true ./montage-ai.sh run --upscale --cgpu-gpu`

Fallback order for upscaling: cgpu T4/A100 â†’ local Vulkan GPU â†’ FFmpeg Lanczos (CPU).

## Creative Loop (Agentic Refinement)

When enabled, the LLM evaluates each cut and suggests improvements:

```bash
CREATIVE_LOOP=true ./montage-ai.sh run hitchcock
```

**How it works:**
1. First cut is built with initial editing instructions
2. LLM evaluates pacing, variety, energy, transitions
3. If satisfaction score < 80%, adjustments are applied
4. Process repeats until approved or max iterations (default: 3)

**Evaluation criteria:**
- **Pacing:** Does cut rhythm match the style and music energy?
- **Variety:** Enough shot variation? No jump cuts or repetition?
- **Energy:** Fast cuts on high-energy sections, breathing room on calm ones?
- **Story Arc:** Does the edit follow intro â†’ build â†’ climax â†’ outro?

See [configuration.md](configuration.md#creative-loop-agentic-refinement) for all options.

## Shorts Workflow (Vertical Video) {#shorts-workflow}

> **Note:** The full Shorts Studio UI is available at `/shorts`. This section covers CLI usage.

- **Smart Reframing**: Automatically crops horizontal footage to 9:16 vertical aspect ratio using face detection and segmented tracking.
- **Segmented Tracking**: Stabilizes camera movement by keeping the crop window static until the subject moves significantly, preventing jitter.
- **Auto-Captions**: Generates and burns in subtitles (requires `whisper`).
- **Web UI Integration**: Toggle "Shorts Mode" in the Web UI for easy creation.

**CLI usage:**
```bash
# Basic vertical output
./montage-ai.sh run viral --aspect 9:16

# With captions
./montage-ai.sh run viral --aspect 9:16 --captions

# High quality shorts
./montage-ai.sh run viral --aspect 9:16 --quality high --captions
```

---

## API Reference

The Web UI exposes a REST API for automation:

### Core Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/status` | GET | Health check |
| `/api/files` | GET | List uploaded files |
| `/api/upload` | POST | Upload video/music (multipart) |
| `/api/jobs` | POST | Create montage job |
| `/api/jobs/{id}` | GET | Job status |
| `/api/download/{file}` | GET | Download output |

### Transcript Editor

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/transcript/upload` | POST | Upload video for editing |
| `/api/transcript/transcribe` | POST | Generate transcript |
| `/api/transcript/export` | POST | Export edited video/EDL/OTIO |

**Export formats:** `video`, `edl`, `otio`

### Shorts Studio

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/shorts/upload` | POST | Upload video for shorts |
| `/api/shorts/analyze` | POST | Analyze for smart reframing |
| `/api/shorts/highlights` | POST | Detect highlight moments |
| `/api/shorts/render` | POST | Render vertical video |
| `/api/shorts/create` | POST | Alias for render |

**Highlight types:** Energy, Drop, Speech, Beat

### Audio Polish

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/audio/clean` | POST | One-click voice isolation + noise reduction |
| `/api/audio/analyze` | POST | Analyze audio quality, get recommendations |

### Quality Profiles

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/quality-profiles` | GET | Get available profiles |
| `/api/cloud/status` | GET | Check cloud acceleration availability |

**Example: Create a job via API**
```bash
curl -X POST http://localhost:8080/api/jobs \
  -H "Content-Type: application/json" \
  -d '{
    "style": "hitchcock",
    "quality_profile": "high",
    "cloud_acceleration": false,
    "export_timeline": true
  }'
```

**Example: Clean audio**
```bash
curl -X POST http://localhost:8080/api/audio/clean \
  -H "Content-Type: application/json" \
  -d '{
    "audio_path": "/data/output/my_video.mp4",
    "isolate_voice": true,
    "reduce_noise": true
  }'
```

**Example: Detect highlights**
```bash
curl -X POST http://localhost:8080/api/shorts/highlights \
  -H "Content-Type: application/json" \
  -d '{
    "video_path": "/data/output/my_video.mp4",
    "max_clips": 5,
    "min_duration": 5,
    "include_speech": true
  }'
```

---

## Troubleshooting

Having issues? Check [troubleshooting.md](troubleshooting.md) for common fixes.

---

## See Also

- [Configuration](configuration.md) â€” All settings explained
- [Architecture](architecture.md) â€” How it works under the hood
- [Strategy](STRATEGY.md) â€” Product vision and roadmap
- [Backlog](BACKLOG.md) â€” Upcoming features
